{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RNzl-GpDAPc"
   },
   "source": [
    "<img src=\"https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png\" srcset=\"https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_130 130w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_260 260w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_390 390w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_520 520w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_650 650w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_780 780w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_910 910w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1040 1040w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1170 1170w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1290 1290w\" sizes=\"100vw\" width=\"1290\">\n",
    "\n",
    "# Simple Chat with Message History\n",
    "\n",
    "In this lab, you'll implement a simple chat interface with message history using LangChain. The chat will:\n",
    "\n",
    "1. Maintain a history of all messages\n",
    "2. Allow adding new messages\n",
    "3. Use the history as context for responses\n",
    "4. Store both user and AI messages in the conversation\n",
    "\n",
    "Tasks and details:\n",
    "* All parts where you should implement something are marked with \"...\" or a sentence starting with \"Task: \"\n",
    "* You'll implement a chat system that remembers context from previous messages\n",
    "* The system must properly handle message history and use it for generating responses\n",
    "* The chat should maintain a professional and helpful tone\n",
    "\n",
    "If you need help:\n",
    "* Use the LangChain chat bot for anything about LangChain: https://chat.langchain.com/\n",
    "* For general questions you can use ChatGPT - or free https://huggingface.co/chat/ with nvidia/Llama-3.1-Nemotron-70B-Instruct-HF LLM - you need a free HuggingFace account to login\n",
    "* Look at the LangChain documentation for `RunnableWithMessageHistory` and `ChatMessageHistory`: https://python.langchain.com/docs/versions/migrating_memory/chat_history/#using-with-runnablewithmessagehistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-asV-GNgDAPd"
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required packages and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmJME2MvDAPd"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain==0.3.7 langchain-openai==0.2.5 langchain-community==0.3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4ajkeAsDAPe"
   },
   "source": [
    "### Read environment variables from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRcg_u0kDAPe"
   },
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_7vLorZDAPe"
   },
   "source": [
    "## Available LLMs\n",
    "\n",
    "Let's use OpenAI for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25J0TXFbDAPe"
   },
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "TEMPERATURE = 0\n",
    "MAX_TOKENS = 1500\n",
    "\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "BASE_URL = \"https://api.openai.com/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6kRH5QGDAPf"
   },
   "source": [
    "## Initialize Chat Components\n",
    "\n",
    "Now we'll set up our chat model and message history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDD56tvVDAPf"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Task: Initialize the chat model\n",
    "chat = ...\n",
    "\n",
    "# Task: Create a prompt template with system message and placeholders for history and input\n",
    "prompt = ...\n",
    "\n",
    "# Task: Create the basic chain\n",
    "chain = ...\n",
    "\n",
    "# Task: Initialize message history\n",
    "message_history = ...\n",
    "\n",
    "# Task: Create a chain with message history\n",
    "chain_with_history = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NL1yu11hDAPf"
   },
   "source": [
    "## Chat Interface\n",
    "\n",
    "Let's create a simple function to handle chat interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g696tJQuDAPf"
   },
   "outputs": [],
   "source": [
    "def chat_with_history(user_input: str):\n",
    "    \"\"\"Send a message to the chat and get a response\"\"\"\n",
    "    # Task: Implement the chat function that:\n",
    "    # 1. Takes user input\n",
    "    # 2. Sends it through the chain with history\n",
    "    # 3. Prints the assistant's response\n",
    "    # 4. Shows the current message history\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80aOlXiNDAPg"
   },
   "source": [
    "## Try it out!\n",
    "\n",
    "Let's test our chat with some example interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTJz92qgDAPg"
   },
   "outputs": [],
   "source": [
    "chat_with_history(\"Hi! My name is Alice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOlyRJRFDAPg"
   },
   "outputs": [],
   "source": [
    "chat_with_history(\"What's my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPQA1LgmDAPg"
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "Type your message in the cell below and run it to chat with the AI. The assistant will remember the context of your conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eY68xtjKDAPg"
   },
   "outputs": [],
   "source": [
    "chat_with_history(\"Your message here\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
